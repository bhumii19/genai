import torch
import torch.nn.functional as F

x = torch.rand(1, 3, 4)
Q, K, V = x, x, x

scores = torch.matmul(Q, K.transpose(-2, -1)) / (4 ** 0.5)
weights = F.softmax(scores, dim=-1)
output = torch.matmul(weights, V)

print("Attention Weights:", weights)
print("Output:", output)

THEORY - 
Here‚Äôs the related theory and explanation for your **Self-Attention mechanism code**:

---

### 1. What is Self-Attention?

* Self-Attention is the **core of the Transformer architecture** (used in BERT, GPT, etc.).
* It allows each token in a sequence to **attend (focus) on other tokens** when creating its representation.
* This helps capture **long-range dependencies** and contextual meaning in sequences (like words in a sentence).

---

### 2. Key Components

* **Q (Query), K (Key), V (Value):**

  * Derived from the same input (`x`) using linear projections.
  * In your code: `Q = K = V = x`.

* **Attention Scores:**

  $$
  \text{scores} = \frac{Q \cdot K^T}{\sqrt{d_k}}
  $$

  * Measures similarity between queries and keys.
  * `d_k` = dimension of key (here 4).

* **Softmax Weights:**

  $$
  \text{weights} = \text{softmax}(\text{scores})
  $$

  * Converts scores into probabilities (how much focus to give to each token).

* **Output:**

  $$
  \text{output} = \text{weights} \cdot V
  $$

  * Weighted sum of values, giving new contextualized embeddings.

---

### 3. About the Code

1. **Input Tensor**

   ```python
   x = torch.rand(1, 3, 4)
   ```

   * Shape `(batch=1, sequence_length=3, features=4)`.
   * Example: a sequence of 3 tokens, each with 4-dimensional embeddings.

2. **Attention Scores**

   ```python
   scores = torch.matmul(Q, K.transpose(-2, -1)) / (4 ** 0.5)
   ```

   * Computes similarity between each pair of tokens.
   * Shape: `(1, 3, 3)` ‚Üí each token attends to 3 tokens (including itself).

3. **Attention Weights**

   ```python
   weights = F.softmax(scores, dim=-1)
   ```

   * Normalizes scores into probabilities.
   * Example: `[0.6, 0.3, 0.1]` ‚Üí token attends mostly to the first token.

4. **Output**

   ```python
   output = torch.matmul(weights, V)
   ```

   * Shape: `(1, 3, 4)` ‚Üí same as input, but now embeddings are **context-aware**.

---

### 4. Why Self-Attention is Important in Generative AI

* Captures **relationships between words** regardless of distance.
* Example: In the sentence *‚ÄúThe cat that sat on the mat was black‚Äù*, self-attention helps connect *‚Äúcat‚Äù* and *‚Äúblack‚Äù*.
* Enables **parallel processing** (unlike RNNs which are sequential).
* Foundation of **Transformers, GPT, BERT, Diffusion Models, Vision Transformers (ViTs)**.

---

üëâ Do you want me to also show a **step-by-step numeric example** of how attention weights are computed for a small sequence (like with actual numbers instead of random tensors)?


